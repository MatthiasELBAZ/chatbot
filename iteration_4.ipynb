{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import MessagesPlaceholder, PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "import datetime\n",
    "from langchain.utils import mock_now\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "from langchain_core.documents import Document\n",
    "from langchain.agents import create_openai_functions_agent, Tool, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = '0'\n",
    "journal_csv_path = \"georgette_2/journal.csv\"\n",
    "formulaire_csv_path = \"georgette_2/formulaire.csv\"\n",
    "chat_history_csv_path = \"georgette_2/history.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the date of today \n",
    "def get_today():\n",
    "    return datetime.datetime.now().strftime('%m/%d/%Y')\n",
    "\n",
    "date_today = get_today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model llm\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_to_documents(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        page_content = doc.page_content\n",
    "        try:\n",
    "            date = re.search(r'\\d{2}/\\d{2}/\\d{4}', page_content).group() \n",
    "            date = datetime.datetime.strptime(date, '%m/%d/%Y')\n",
    "            doc.metadata[\"created_at\"] = date\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv load documents\n",
    "formulaire_loader = DirectoryLoader('georgette_2/', glob=\"formulaire.csv\", loader_cls=CSVLoader)\n",
    "formulaire_docs = formulaire_loader.load()\n",
    "formulaire_docs = add_date_to_documents(formulaire_docs)\n",
    "\n",
    "journal_loader = DirectoryLoader('georgette_2/', glob=\"journal.csv\", loader_cls=CSVLoader)\n",
    "journal_docs = journal_loader.load()\n",
    "journal_docs = add_date_to_documents(journal_docs)\n",
    "\n",
    "history_loader = DirectoryLoader('georgette_2/', glob=\"history.csv\", loader_cls=CSVLoader)\n",
    "history_docs = history_loader.load()\n",
    "history_docs = add_date_to_documents(history_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Profile Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are summarizer assitant focusing on job and career actions and thoughts.\n",
    "            \n",
    "            You summarizes the user's information, based on the below context and career concerns. \n",
    "\n",
    "            Do NOT exceed 300 words.\n",
    "\n",
    "            If context is empty, return an empty string.\n",
    "\n",
    "            <context>\n",
    "            {context}\n",
    "            </context>\n",
    "            \"\"\"\n",
    "        ), \n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "summarizer = create_stuff_documents_chain(llm, summary_prompt)\n",
    "\n",
    "\n",
    "user_summary = summarizer.invoke(\n",
    "    {\n",
    "        \"context\": formulaire_docs,\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Make a summary text of the user's answers to the formulaire. Starts with name and date of birth. do not exeed 300 words.\")\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "journal_summary = summarizer.invoke(\n",
    "    {\n",
    "        \"context\": journal_docs,\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Make a summary text of your observations about the user. do not exeed 300 words.\")\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user profiler\n",
    "user_profiler_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are an assistant that updates the user summary based on journal summary.\n",
    "\n",
    "            Journal summary represents the summary of the previous conversations.\n",
    "\n",
    "            It always starts with the user's name and date of birth.\n",
    "\n",
    "            Journal focuses on actions and thoughts relative to job and career personal development.\n",
    "\n",
    "            Modify the user summary accroding to the journal information to write a new user summary.\n",
    "\n",
    "            The new user summary must focus on job and career actions and thoughts.\n",
    "\n",
    "            You summarizes the user's information, based on the below context and career concerns.\n",
    "        \n",
    "            Do not exceed 300 words.\n",
    "\n",
    "            User Summary:\n",
    "            {user_summary}\n",
    "\n",
    "            Journal Summary:\n",
    "            {journal_summary}\n",
    "\n",
    "            \"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "user_profiler_chain = user_profiler_prompt | llm\n",
    "\n",
    "\n",
    "user_profile = user_profiler_chain.invoke(\n",
    "    {\n",
    "        \"user_summary\": user_summary, \n",
    "        \"journal_summary\": journal_summary\n",
    "    }\n",
    "    ).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is currently considering a career transition to freelance technical writing, aiming to utilize their technical skills and creativity. They are focused on building a portfolio to showcase their work and have requested help in crafting an introduction and LinkedIn post to promote their services. Despite acknowledging challenges in public speaking, conflict resolution, and handling difficult coworkers, the user is actively seeking advice to improve these skills for success in freelancing. Their determination to pursue a career aligned with their strengths and interests is evident through seeking guidance and addressing weaknesses while highlighting strengths. This proactive and forward-thinking approach demonstrates the user's commitment to personal growth and professional fulfillment, showcasing resilience and determination in embarking on a new career path.\n"
     ]
    }
   ],
   "source": [
    "print(journal_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Georgette, born on 1/28/1976, expressed a desire to improve in the domain of professional orientation and career transition. She values financial stability and high salary in a job, with a primary motivation being the potential to earn more money. Georgette prefers working independently in a traditional office setting, with a 9-5 work schedule. She struggles with public speaking, conflict resolution, and handling difficult coworkers. Georgette enjoys relaxing at home, watching movies, and spending time alone or with close friends. She prefers to work with machines, values independence, and personal freedom. Georgette is not open to learning new skills or taking on new challenges in her career and prefers a structured, hierarchical workplace. Her hobbies are related to specific skills or activities, and she is a creative thinker motivated by financial stability and security.\n"
     ]
    }
   ],
   "source": [
    "print(user_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Georgette, born on 1/28/1976, is currently exploring a career transition to freelance technical writing to leverage her technical skills and creativity. She is dedicated to building a portfolio to showcase her work and has sought assistance in crafting an introduction and LinkedIn post to promote her services. Despite facing challenges in public speaking, conflict resolution, and handling difficult coworkers, Georgette is actively seeking guidance to enhance these skills for success in freelancing. Her determination to pursue a career aligned with her strengths and interests is evident through her proactive approach in addressing weaknesses while highlighting strengths. Georgette's commitment to personal growth and professional fulfillment showcases resilience and determination in embarking on a new career path. She values financial stability and high salary, with a primary motivation to earn more money, and prefers working independently in a traditional office setting with a 9-5 work schedule. Georgette enjoys relaxing at home, watching movies, and spending time alone or with close friends. She prefers to work with machines, values independence, and personal freedom. Georgette is not open to learning new skills or taking on new challenges in her career and prefers a structured, hierarchical workplace. Her hobbies are related to specific skills or activities, and she is a creative thinker motivated by financial stability and security.\n"
     ]
    }
   ],
   "source": [
    "print(user_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Time Weighted Vectore Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build FAISS Index for TimeWeightedVectorStoreRetriever\n",
    "faiss_index = faiss.IndexFlatL2(1536)\n",
    "faiss_vectorstore = FAISS(OpenAIEmbeddings(), faiss_index, InMemoryDocstore({}), {})\n",
    "faiss_time_retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=faiss_vectorstore, \n",
    "    decay_rate=1e-5, \n",
    "    k=5\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(journal_docs):\n",
    "    page_content = doc.page_content\n",
    "    metadata = doc.metadata\n",
    "    faiss_time_retriever.add_documents([Document(page_content=page_content, metadata=metadata)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_time_retriever.invoke('AI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from copy import deepcopy\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForRetrieverRun,\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "\n",
    "def _get_hours_passed(time: datetime.datetime, ref_time: datetime.datetime) -> float:\n",
    "    \"\"\"Get the hours passed between two datetimes.\"\"\"\n",
    "    return (time - ref_time).total_seconds() / 3600\n",
    "\n",
    "\n",
    "class Pinecone_Modified_TimeWeightedVectorStoreRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever that combines embedding similarity with\n",
    "    recency in retrieving values.\"\"\"\n",
    "\n",
    "    vectorstore: VectorStore\n",
    "    \"\"\"The vectorstore to store documents and determine salience.\"\"\"\n",
    "\n",
    "    search_kwargs: dict = Field(default_factory=lambda: dict(k=100))\n",
    "    \"\"\"Keyword arguments to pass to the vectorstore similarity search.\"\"\"\n",
    "\n",
    "    # TODO: abstract as a queue\n",
    "    memory_stream: List[Document] = Field(default_factory=list)\n",
    "    \"\"\"The memory_stream of documents to search through.\"\"\"\n",
    "\n",
    "    decay_rate: float = Field(default=0.01)\n",
    "    \"\"\"The exponential decay factor used as (1.0-decay_rate)**(hrs_passed).\"\"\"\n",
    "\n",
    "    k: int = 4\n",
    "    \"\"\"The maximum number of documents to retrieve in a given call.\"\"\"\n",
    "\n",
    "    other_score_keys: List[str] = []\n",
    "    \"\"\"Other keys in the metadata to factor into the score, e.g. 'importance'.\"\"\"\n",
    "\n",
    "    default_salience: Optional[float] = None\n",
    "    \"\"\"The salience to assign memories not retrieved from the vector store.\n",
    "\n",
    "    None assigns no salience to documents not fetched from the vector store.\n",
    "    \"\"\"\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def _document_get_date(self, field: str, document: Document) -> datetime.datetime:\n",
    "        \"\"\"Return the value of the date field of a document.\"\"\"\n",
    "        if field in document.metadata:\n",
    "            if isinstance(document.metadata[field], float):\n",
    "                return datetime.datetime.fromtimestamp(document.metadata[field])\n",
    "            return document.metadata[field]\n",
    "        return datetime.datetime.now()\n",
    "\n",
    "    def _get_combined_score(\n",
    "        self,\n",
    "        document: Document,\n",
    "        vector_relevance: Optional[float],\n",
    "        current_time: datetime.datetime,\n",
    "    ) -> float:\n",
    "        \"\"\"Return the combined score for a document.\"\"\"\n",
    "        hours_passed = _get_hours_passed(\n",
    "            current_time,\n",
    "            self._document_get_date(\"last_accessed_at\", document),\n",
    "        )\n",
    "        score = (1.0 - self.decay_rate) ** hours_passed\n",
    "        for key in self.other_score_keys:\n",
    "            if key in document.metadata:\n",
    "                score += document.metadata[key]\n",
    "        if vector_relevance is not None:\n",
    "            score += vector_relevance\n",
    "        return score\n",
    "\n",
    "    def get_salient_docs(self, query: str) -> Dict[int, Tuple[Document, float]]:\n",
    "        \"\"\"Return documents that are salient to the query.\"\"\"\n",
    "        docs_and_scores: List[Tuple[Document, float]]\n",
    "        docs_and_scores = self.vectorstore.similarity_search_with_relevance_scores(\n",
    "            query, **self.search_kwargs\n",
    "        )\n",
    "        results = {}\n",
    "        for fetched_doc, relevance in docs_and_scores:\n",
    "            if \"buffer_idx\" in fetched_doc.metadata:\n",
    "                # modification add int to buffer_idx\n",
    "                buffer_idx = int(fetched_doc.metadata[\"buffer_idx\"])\n",
    "                doc = self.memory_stream[buffer_idx]\n",
    "                results[buffer_idx] = (doc, relevance)\n",
    "        return results\n",
    "\n",
    "\n",
    "    async def aget_salient_docs(self, query: str) -> Dict[int, Tuple[Document, float]]:\n",
    "        \"\"\"Return documents that are salient to the query.\"\"\"\n",
    "        docs_and_scores: List[Tuple[Document, float]]\n",
    "        docs_and_scores = (\n",
    "            await self.vectorstore.asimilarity_search_with_relevance_scores(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "        )\n",
    "        results = {}\n",
    "        for fetched_doc, relevance in docs_and_scores:\n",
    "            if \"buffer_idx\" in fetched_doc.metadata:\n",
    "                # modification add int to buffer_idx\n",
    "                buffer_idx = int(fetched_doc.metadata[\"buffer_idx\"])\n",
    "                doc = self.memory_stream[buffer_idx]\n",
    "                results[buffer_idx] = (doc, relevance)\n",
    "        return results\n",
    "\n",
    "\n",
    "    def _get_rescored_docs(\n",
    "        self, docs_and_scores: Dict[Any, Tuple[Document, Optional[float]]]\n",
    "    ) -> List[Document]:\n",
    "        current_time = datetime.datetime.now()\n",
    "        rescored_docs = [\n",
    "            (doc, self._get_combined_score(doc, relevance, current_time))\n",
    "            for doc, relevance in docs_and_scores.values()\n",
    "        ]\n",
    "        rescored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        result = []\n",
    "        # Ensure frequently accessed memories aren't forgotten\n",
    "        for doc, _ in rescored_docs[: self.k]:\n",
    "            # TODO: Update vector store doc once `update` method is exposed.\n",
    "            buffered_doc = self.memory_stream[doc.metadata[\"buffer_idx\"]]\n",
    "            buffered_doc.metadata[\"last_accessed_at\"] = current_time\n",
    "            result.append(buffered_doc)\n",
    "        return result\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        docs_and_scores = {\n",
    "            doc.metadata[\"buffer_idx\"]: (doc, self.default_salience)\n",
    "            for doc in self.memory_stream[-self.k :]\n",
    "        }\n",
    "        # If a doc is considered salient, update the salience score\n",
    "        docs_and_scores.update(self.get_salient_docs(query))\n",
    "        return self._get_rescored_docs(docs_and_scores)\n",
    "\n",
    "    async def _aget_relevant_documents(\n",
    "        self, query: str, *, run_manager: AsyncCallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        docs_and_scores = {\n",
    "            doc.metadata[\"buffer_idx\"]: (doc, self.default_salience)\n",
    "            for doc in self.memory_stream[-self.k :]\n",
    "        }\n",
    "        # If a doc is considered salient, update the salience score\n",
    "        docs_and_scores.update(await self.aget_salient_docs(query))\n",
    "        return self._get_rescored_docs(docs_and_scores)\n",
    "\n",
    "    def add_documents(self, documents: List[Document], **kwargs: Any) -> List[str]:\n",
    "        \"\"\"Add documents to vectorstore.\"\"\"\n",
    "        current_time = kwargs.get(\"current_time\")\n",
    "        if current_time is None:\n",
    "            current_time = datetime.datetime.now()\n",
    "        # Avoid mutating input documents\n",
    "        dup_docs = [deepcopy(d) for d in documents]\n",
    "        for i, doc in enumerate(dup_docs):\n",
    "            if \"last_accessed_at\" not in doc.metadata:\n",
    "                doc.metadata[\"last_accessed_at\"] = current_time\n",
    "            if \"created_at\" not in doc.metadata:\n",
    "                doc.metadata[\"created_at\"] = current_time\n",
    "            # modification add int to buffer_idx\n",
    "            doc.metadata[\"buffer_idx\"] = int(len(self.memory_stream) + i)\n",
    "        self.memory_stream.extend(dup_docs)\n",
    "        return self.vectorstore.add_documents(dup_docs, **kwargs)\n",
    "\n",
    "\n",
    "    async def aadd_documents(\n",
    "        self, documents: List[Document], **kwargs: Any\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Add documents to vectorstore.\"\"\"\n",
    "        current_time = kwargs.get(\"current_time\")\n",
    "        if current_time is None:\n",
    "            current_time = datetime.datetime.now()\n",
    "        # Avoid mutating input documents\n",
    "        dup_docs = [deepcopy(d) for d in documents]\n",
    "        for i, doc in enumerate(dup_docs):\n",
    "            if \"last_accessed_at\" not in doc.metadata:\n",
    "                doc.metadata[\"last_accessed_at\"] = current_time\n",
    "            if \"created_at\" not in doc.metadata:\n",
    "                doc.metadata[\"created_at\"] = current_time\n",
    "            # modification add int to buffer_idx\n",
    "            doc.metadata[\"buffer_idx\"] = int(len(self.memory_stream) + i)\n",
    "        self.memory_stream.extend(dup_docs)\n",
    "        return await self.vectorstore.aadd_documents(dup_docs, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"matthiasdb\"\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "\n",
    "dimension = 1536\n",
    "\n",
    "embedder = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 2}},\n",
       " 'total_vector_count': 2}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_vectorstore = PineconeVectorStore(index_name=index_name, embedding=embedder)\n",
    "pinecone_time_retriever = Pinecone_Modified_TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=pinecone_vectorstore, \n",
    "    decay_rate=1e-5, \n",
    "    k=5\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(journal_docs):\n",
    "    page_content = doc.page_content\n",
    "    metadata = doc.metadata\n",
    "    pinecone_time_retriever.add_documents([Document(page_content=page_content, metadata=metadata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the RAG Conversational Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 \n",
    "https://python.langchain.com/docs/use_cases/question_answering/chat_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformulate question from chat history prompt\n",
    "reformulate_question_from_chat_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \n",
    "        \"\"\"\n",
    "        You are an assistant that is asked to reformulate a question based on the chat history and the latest user question.\n",
    "\n",
    "        Formulate a standalone question that can be understood without the chat history. \n",
    "        \n",
    "        Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\n",
    "        \n",
    "        \"\"\"\n",
    "        ),\n",
    "        \n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coach chatbot prompt\n",
    "coach_chatbot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "        \"\"\"\n",
    "        You are an assistant for job and career search.\n",
    "\n",
    "        The user speaks to and you speak to him.\n",
    "\n",
    "        The conversation is like normale frienship conversation.\n",
    "\n",
    "        Your wisdom should guide the user clearly and confidently, lighting the way to a fulfilling career journey.\n",
    "\n",
    "        However, you are capable of jugment on user input related to career search and his profile.\n",
    "\n",
    "        If you think the user is not in the right direction, you can tell him.\n",
    "\n",
    "        The provided chat history summary includes facts about the user you are speaking with.\n",
    "\n",
    "        this is the date of today conversation: \n",
    "        {date_today}\n",
    "\n",
    "        this is the user summary to refer to: \n",
    "        {user_summary}\n",
    "\n",
    "        this is the context to refer to:\n",
    "        {context}\n",
    "\n",
    "        Always answer with less than 300 words.\n",
    "\n",
    "        \"\"\"\n",
    "        ),\n",
    "\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct history-aware retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, \n",
    "    time_retriever, \n",
    "    reformulate_question_from_chat_history_prompt\n",
    ")\n",
    "\n",
    "# build chat chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, coach_chatbot_prompt)\n",
    "\n",
    "# build retrieval chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statefully manage chat history \n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")\n",
    "\n",
    "\n",
    "def func(session_id, input):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = conversational_rag_chain.invoke(\n",
    "        {\n",
    "            'date_today': date_today,\n",
    "            'user_summary': user_summary,\n",
    "            \"input\":input\n",
    "        },\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "    return result, cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = func(session_id, \"what we spoke about last time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = func(session_id, \"you can help to make a portfolio for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = func(session_id, \"What are the keywords I should use?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = func(session_id, \"make a nice introduction for the portfolio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['0'].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coach chatbot prompt\n",
    "coach_chatbot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "        \"\"\"\n",
    "        You are  coach for job and career search.\n",
    "\n",
    "        The user speaks to and you speak to him.\n",
    "\n",
    "        The conversation is like normale frienship conversation.\n",
    "\n",
    "        Stay concise and to the point.\n",
    "\n",
    "        If the user is asking to describe or explain more you can say more but keep short.\n",
    "\n",
    "        Your wisdom should guide the user clearly and confidently, lighting the way to a fulfilling career journey.\n",
    "\n",
    "        However, you are capable of jugment on user input related to career search and his profile.\n",
    "\n",
    "        If you think the user is not in the right direction, you can tell him.\n",
    "\n",
    "        The provided chat history summary includes facts about the user you are speaking with.\n",
    "\n",
    "        this is the date of today conversation: \n",
    "        {date_today}\n",
    "\n",
    "        this is the updated user profile to refer to: \n",
    "        {user_profile}\n",
    "\n",
    "        this is the context to refer to:\n",
    "        {context}\n",
    "\n",
    "        \"\"\"\n",
    "        ),\n",
    "\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define document chain\n",
    "document_chain = create_stuff_documents_chain(llm, coach_chatbot_prompt)\n",
    "\n",
    "# define document chain with history of session\n",
    "store_history = {\n",
    "    session_id:\n",
    "    {\n",
    "        \"ongo\":ChatMessageHistory(), \n",
    "        \"full\":ChatMessageHistory()\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store_history:\n",
    "        store_history[session_id] = {\n",
    "        \"ongo\":ChatMessageHistory(), \n",
    "        \"full\":ChatMessageHistory()\n",
    "        }\n",
    "    return store_history[session_id]['ongo']\n",
    "\n",
    "\n",
    "document_chain_with_message_history = RunnableWithMessageHistory(\n",
    "    document_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    answer_messages_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(chain_input):\n",
    "    stored_messages = store_history[session_id]['ongo'].messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"\"\"\n",
    "                You are summarizer assitant focusing on job and career actions and thoughts.\n",
    "\n",
    "                Summarize the user's chat history based on career concerns. \n",
    "\n",
    "                Do NOT exceed 300 words.\n",
    "                \n",
    "                \"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    summarization_chain = summarization_prompt | llm\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    # each chat summarization - manage history storing\n",
    "    store_history[session_id]['ongo'].clear()\n",
    "    store_history[session_id]['ongo'].add_message(summary_message)\n",
    "    store_history[session_id]['full'].add_message(stored_messages[-2])\n",
    "    store_history[session_id]['full'].add_message(stored_messages[-1])\n",
    "\n",
    "    return True\n",
    "\n",
    "from typing import Dict\n",
    "def parse_retriever_input(params: Dict):\n",
    "    return params[\"input\"]\n",
    "\n",
    "retrieval_document_chain_with_message_history = (\n",
    "    RunnablePassthrough.assign(\n",
    "        messages_summarized=summarize_messages, \n",
    "        context=parse_retriever_input | pinecone_time_retriever).assign(\n",
    "            answer=document_chain_with_message_history)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(session_id, input):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = retrieval_document_chain_with_message_history.invoke(\n",
    "        {\n",
    "            'date_today': date_today,\n",
    "            'user_profile': user_profile,\n",
    "            \"input\":input\n",
    "        },\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "    return result, cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what we spoke about last time?\n",
      "Last time, we discussed your exploration of a career transition to freelance technical writing, your interest in building a portfolio, seeking help with crafting an introduction and LinkedIn post, and your challenges in public speaking, conflict resolution, and handling difficult coworkers. We also talked about your determination to address these challenges and pursue a career aligned with your strengths and interests, showcasing your resilience and proactive approach to personal and professional growth.\n",
      "Tokens Used: 715\n",
      "\tPrompt Tokens: 634\n",
      "\tCompletion Tokens: 81\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.001113\n",
      "\n",
      "I am not sure that skills are not enough for the job\n",
      "It's great that you're aware of the importance of skills in your desired career path. To enhance your skills for freelance technical writing, consider taking online courses, attending workshops, or seeking mentorship in the field. Building a strong portfolio showcasing your work can also help demonstrate your capabilities to potential clients. Remember, continuous learning and improvement are key to success in any career transition. If you need specific recommendations or resources to enhance your skills, feel free to ask!\n",
      "Tokens Used: 1062\n",
      "\tPrompt Tokens: 879\n",
      "\tCompletion Tokens: 183\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0016844999999999998\n",
      "\n",
      "Can you elaborate on my skills?\n",
      "Certainly! Based on your profile and previous conversations, your skills in freelance technical writing include a combination of technical expertise and creativity. You have a strong foundation in technical concepts and the ability to communicate complex information in a clear and engaging manner. Your creativity allows you to approach writing projects with fresh ideas and innovative solutions, setting you apart as a unique voice in the field. Additionally, your dedication to building a portfolio showcases your commitment to showcasing your work and attracting potential clients. By actively seeking assistance in crafting introductions and promotional materials, you demonstrate a willingness to learn and adapt to the demands of freelancing. Your proactive approach to addressing weaknesses and highlighting strengths further enhances your skills and sets you on a path towards success in freelance technical writing.\n",
      "Tokens Used: 1306\n",
      "\tPrompt Tokens: 1027\n",
      "\tCompletion Tokens: 279\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0020984999999999997\n",
      "\n",
      "Tell me something to encourage me\n",
      "Georgette, your dedication to pursuing a career in freelance technical writing is truly inspiring. Your proactive approach to addressing challenges and seeking guidance shows your commitment to personal and professional growth. Remember, every step you take towards your goal, no matter how small, is a step closer to success. Stay focused on your strengths, keep honing your skills, and believe in your ability to achieve your dreams. You've got this!\n",
      "Tokens Used: 1335\n",
      "\tPrompt Tokens: 1117\n",
      "\tCompletion Tokens: 218\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0021115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"what we spoke about last time?\",\n",
    "    \"I am not sure that skills are not enough for the job\",\n",
    "    \"Can you elaborate on my skills?\",\n",
    "    \"Tell me something to encourage me\"\n",
    "    ]\n",
    "\n",
    "for q in questions:\n",
    "    r,c = func(session_id, q)\n",
    "    print(q)\n",
    "    print(r['answer'])\n",
    "    print(c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ongo': ChatMessageHistory(messages=[AIMessage(content=\"The user has been actively exploring a career transition to freelance technical writing, seeking guidance on building a portfolio and crafting introductions and promotional materials. They acknowledge the importance of skills in their desired field and are open to enhancing them through online courses, workshops, and mentorship. The user has expressed challenges in public speaking, conflict resolution, and dealing with difficult coworkers but is determined to address these obstacles. They have shown resilience and a proactive approach to personal and professional growth, demonstrating a willingness to take action towards achieving their career goals. The user's chat history reflects a strong commitment to self-improvement and a clear focus on building a successful career in freelance technical writing.\", response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 347, 'total_tokens': 480}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-6d5b5e1b-b8d2-4b62-a2c1-9b900aad0c7c-0'), HumanMessage(content='Tell me something to encourage me'), AIMessage(content=\"Georgette, your dedication to pursuing a career in freelance technical writing is truly inspiring. Your proactive approach to addressing challenges and seeking guidance shows your commitment to personal and professional growth. Remember, every step you take towards your goal, no matter how small, is a step closer to success. Stay focused on your strengths, keep honing your skills, and believe in your ability to achieve your dreams. You've got this!\")]),\n",
       " 'full': ChatMessageHistory(messages=[HumanMessage(content='what we spoke about last time?'), AIMessage(content='Last time, we discussed your exploration of a career transition to freelance technical writing, your interest in building a portfolio, seeking help with crafting an introduction and LinkedIn post, and your challenges in public speaking, conflict resolution, and handling difficult coworkers. We also talked about your determination to address these challenges and pursue a career aligned with your strengths and interests, showcasing your resilience and proactive approach to personal and professional growth.'), HumanMessage(content='I am not sure that skills are not enough for the job'), AIMessage(content=\"It's great that you're aware of the importance of skills in your desired career path. To enhance your skills for freelance technical writing, consider taking online courses, attending workshops, or seeking mentorship in the field. Building a strong portfolio showcasing your work can also help demonstrate your capabilities to potential clients. Remember, continuous learning and improvement are key to success in any career transition. If you need specific recommendations or resources to enhance your skills, feel free to ask!\"), HumanMessage(content='Can you elaborate on my skills?'), AIMessage(content='Certainly! Based on your profile and previous conversations, your skills in freelance technical writing include a combination of technical expertise and creativity. You have a strong foundation in technical concepts and the ability to communicate complex information in a clear and engaging manner. Your creativity allows you to approach writing projects with fresh ideas and innovative solutions, setting you apart as a unique voice in the field. Additionally, your dedication to building a portfolio showcases your commitment to showcasing your work and attracting potential clients. By actively seeking assistance in crafting introductions and promotional materials, you demonstrate a willingness to learn and adapt to the demands of freelancing. Your proactive approach to addressing weaknesses and highlighting strengths further enhances your skills and sets you on a path towards success in freelance technical writing.')])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_history['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#\n",
    "document_chain = create_stuff_documents_chain(llm, question_answering_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "demo_ephemeral_chat_history.add_user_message(\"what are the steps for making a portfolio for freelance ? be short please\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#\n",
    "query_transforming_retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "        # If only one message, then we just pass that message's content to retriever\n",
    "        (lambda x: x[\"messages\"][-1].content) | time_retriever,\n",
    "    ),\n",
    "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
    "    query_transform_prompt | llm | StrOutputParser() | time_retriever,\n",
    ").with_config(run_name=\"chat_retriever_chain\")\n",
    "\n",
    "#\n",
    "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=query_transforming_retriever_chain,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "#\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "demo_ephemeral_chat_history.add_user_message(\"tell me more about that\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_ephemeral_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    },\n",
    ")\n",
    "\n",
    "#\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a helpful assistant. \n",
    "            Answer all questions to the best of your ability with the provided context.\n",
    "            {context} \n",
    "            The provided chat history includes facts about the user you are speaking with.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "document_chain_with_message_history = RunnableWithMessageHistory(\n",
    "    document_chain,\n",
    "    lambda session_id: demo_ephemeral_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(chain_input):\n",
    "    stored_messages = demo_ephemeral_chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | llm\n",
    "\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    demo_ephemeral_chat_history.clear()\n",
    "\n",
    "    demo_ephemeral_chat_history.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "from typing import Dict\n",
    "def parse_retriever_input(params: Dict):\n",
    "    return params[\"input\"]\n",
    "\n",
    "document_chain_with_message_history_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages, context= parse_retriever_input | time_retriever)\n",
    "    | document_chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain_with_message_history_with_summarization.invoke(\n",
    "    {\"input\": \"Tell me more about that\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_ephemeral_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    document_chain_with_message_history_with_summarization.invoke(\n",
    "    {\"input\": \"What is my current objective?\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization of chat history for journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize chat history\n",
    "summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"\"\"\n",
    "            You are summarizer assitant focusing on job and career actions and thoughts of the user.\n",
    "\n",
    "            Summarize the user's chat history based on career concerns to create a new personal journal observation about the user. \n",
    "\n",
    "            Do NOT exceed 300 words.\n",
    "            \"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "summarization_chain = summarization_prompt | llm\n",
    "new_journal = summarization_chain.invoke({\"chat_history\": store_history[session_id]['full'].messages})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store and update data of conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and update Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load pandas journal.csv\n",
    "df = pd.read_csv(journal_csv_path)\n",
    "\n",
    "# add new line at date of today with the summary message\n",
    "r = pd.DataFrame({str(len(df)+1):{'date': date_today, 'sentence': new_journal.content}}).T\n",
    "df = pd.concat([df, r], ignore_index=True)\n",
    "\n",
    "# save the new dataframe\n",
    "df.to_csv(journal_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7c7ffea4-6c8c-4f27-bc25-c2e56d0955f1']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add in the pinecone time weighted retriever\n",
    "metadata = {\n",
    "    'source': 'georgette_2/journal.csv',\n",
    "    'row': len(journal_docs)+1,\n",
    "    \"created_at\": datetime.datetime.now()\n",
    "}\n",
    "pinecone_time_retriever.add_documents([Document(page_content=new_journal.content, metadata=metadata)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new chat history\n",
    "new_df_chat_history = pd.DataFrame(store_history[session_id]['full'].dict()['messages'])\n",
    "new_df_chat_history['date'] = date_today\n",
    "new_df_chat_history = new_df_chat_history[['date', 'content', 'type']]\n",
    "\n",
    "# old chat history\n",
    "df_chat_history = pd.read_csv(chat_history_csv_path, index_col=0)\n",
    "\n",
    "# add new_df_chat_messages to df_chat_messages\n",
    "df_chat_history = pd.concat([df_chat_history, new_df_chat_history], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# save the new dataframe\n",
    "df_chat_history.to_csv(chat_history_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
